{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap  # pip install umap-learn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "from scipy.ndimage import rotate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class MultiDigitRotatedMNISTDataset(Dataset):\n",
    "    \"\"\"\n",
    "    For each digit in [0..9], pick 1 example from MNIST.\n",
    "    For each digit d != 4, keep all angles in [0..360].\n",
    "    For digit 4, skip angles in [140..200].\n",
    "    \"\"\"\n",
    "    def __init__(self, num_angles_per_digit=100, gap_start=140, gap_end=200):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load MNIST (training set)\n",
    "        mnist = datasets.MNIST(\n",
    "            root='./data',\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transforms.ToTensor()\n",
    "        )\n",
    "        \n",
    "        # We'll store one reference image per digit\n",
    "        self.reference_images = {}\n",
    "        for digit in range(10):\n",
    "            idxs = (mnist.targets == digit).nonzero().squeeze()\n",
    "            if len(idxs) == 0:\n",
    "                raise ValueError(f\"No examples of digit {digit} found in MNIST!\")\n",
    "            # Just pick the first occurrence\n",
    "            img = mnist.data[idxs[0]].float() / 255.0  # shape (28, 28)\n",
    "            self.reference_images[digit] = img\n",
    "        \n",
    "        # For each digit, build a list of angles to keep\n",
    "        # We'll store pairs (digit, angle_in_radians) in self.samples\n",
    "        self.samples = []\n",
    "        \n",
    "        # Convert gap angles to radians\n",
    "        gap_start_rad = gap_start * np.pi / 180.0\n",
    "        gap_end_rad   = gap_end   * np.pi / 180.0\n",
    "        \n",
    "        # We'll do a uniform sampling from [0..2π]\n",
    "        # e.g., 0..2π broken into num_angles_per_digit points\n",
    "        for digit in range(10):\n",
    "            all_angles = np.linspace(0, 2*np.pi, num_angles_per_digit, endpoint=False)\n",
    "            \n",
    "            if digit == 4:\n",
    "                # skip angles in [gap_start, gap_end]\n",
    "                def in_gap(a):\n",
    "                    deg = a * 180.0 / np.pi\n",
    "                    return (deg >= gap_start) and (deg <= gap_end)\n",
    "                \n",
    "                # filter out angles in the gap\n",
    "                kept_angles = [a for a in all_angles if not in_gap(a)]\n",
    "            else:\n",
    "                # keep all angles\n",
    "                kept_angles = all_angles\n",
    "            \n",
    "            for a in kept_angles:\n",
    "                self.samples.append( (digit, a) )\n",
    "        \n",
    "        # Pre-rotate all images\n",
    "        self.rotated_images = []\n",
    "        for (digit, angle_rad) in self.samples:\n",
    "            # rotate that digit's reference image\n",
    "            angle_deg = angle_rad * 180.0 / np.pi\n",
    "            rotated = rotate(\n",
    "                self.reference_images[digit].numpy(),\n",
    "                angle_deg,\n",
    "                reshape=False,\n",
    "                order=1,\n",
    "                mode='constant',\n",
    "                cval=0.0\n",
    "            )\n",
    "            self.rotated_images.append( torch.tensor(rotated, dtype=torch.float32) )\n",
    "        \n",
    "        print(f\"Created MultiDigit dataset with total {len(self.samples)} samples.\")\n",
    "        print(f\"Digit=4 has gap in angles [{gap_start}°, {gap_end}°]. Others have full range.\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        digit, angle_rad = self.samples[idx]\n",
    "        img = self.rotated_images[idx]  # shape (28, 28)\n",
    "        \n",
    "        angle_sin = np.sin(angle_rad)\n",
    "        angle_cos = np.cos(angle_rad)\n",
    "        \n",
    "        # Our input: [digit, cos(θ), sin(θ)] or just [cos, sin] if you want\n",
    "        # But we might want the digit as well. For now let's store it as an int in a separate field.\n",
    "        # The model currently only expects 2D input (cos & sin). We'll adapt that next.\n",
    "        \n",
    "        # If you want to feed the digit as well, you'd do something like:\n",
    "        #   return (torch.tensor([digit, angle_cos, angle_sin]),  img.unsqueeze(0))\n",
    "        # But that requires changing the model to input 3D or do an embedding for the digit.\n",
    "        \n",
    "        # If you ONLY feed (cos, sin), the model won't know about digit differences.\n",
    "        # We'll keep it consistent with your current code that expects (2,).\n",
    "        return (torch.tensor([angle_cos, angle_sin], dtype=torch.float32),\n",
    "                img.unsqueeze(0))\n",
    "\n",
    "\n",
    "# Instead of RotatedMNISTDataset(digit=4,...), do:\n",
    "dataset = MultiDigitRotatedMNISTDataset(\n",
    "    num_angles_per_digit=100,\n",
    "    gap_start=140,\n",
    "    gap_end=200\n",
    ")\n",
    "\n",
    "\n",
    "def evaluate_digit4_gap(model, device, num_points=20, store=True):\n",
    "    \"\"\"\n",
    "    Evaluate the model's performance specifically on digit=4\n",
    "    in the previously skipped gap region [140°, 200°].\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    gap_angles_deg = np.linspace(140, 200, num_points)\n",
    "    gap_angles_rad = gap_angles_deg * np.pi / 180.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Build input: for each angle, input is [cos(θ), sin(θ)]\n",
    "        # The model does not currently take the digit as input, \n",
    "        # so it does NOT know that we're generating digit=4 specifically. \n",
    "        # It's just going to produce a rotation it thinks is \"closest\" \n",
    "        # in its learned manifold.\n",
    "        angles_t = torch.tensor([ [np.cos(a), np.sin(a)] for a in gap_angles_rad ], \n",
    "                                dtype=torch.float32, device=device)\n",
    "        \n",
    "        outputs = model(angles_t)  # shape: (num_points, 1, 28, 28)\n",
    "    \n",
    "    plt.figure(figsize=(18, 4))\n",
    "    for i in range(num_points):\n",
    "        plt.subplot(2, num_points//2, i+1)\n",
    "        plt.imshow(outputs[i, 0].cpu().numpy(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"{gap_angles_deg[i]:.1f}° (digit=4 OOD)\")\n",
    "    \n",
    "    plt.suptitle(\"Digit 4: OOD angles [140°,200°]\", color='red')\n",
    "    if store:\n",
    "        plt.savefig('./icml_figs_temp/interpolated_rotated_images_digit4_gap.png', \n",
    "                    bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def visualize_digit4_umap(model, device='cpu', store=True):\n",
    "    \"\"\"\n",
    "    1) Sample 360 angles from 0..2π specifically for digit=4.\n",
    "    2) Hook each layer, collect activations + final outputs.\n",
    "    3) Color ID vs. OOD in [140°, 200°].\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    # 360 angles\n",
    "    num_samples = 360\n",
    "    angles_rad = torch.linspace(0, 2*np.pi, num_samples, device=device)\n",
    "    # For each angle, input is [cos(θ), sin(θ)]\n",
    "    inputs = torch.stack([torch.cos(angles_rad), torch.sin(angles_rad)], dim=1)\n",
    "    \n",
    "    # Hook machinery\n",
    "    collected_activations = {}\n",
    "    def flatten_activation(x):\n",
    "        return x.view(x.size(0), -1)\n",
    "    def make_hook(layer_name):\n",
    "        def hook_fn(module, inp, out):\n",
    "            collected_activations[layer_name] = out.detach().cpu()\n",
    "        return hook_fn\n",
    "\n",
    "    handles = []\n",
    "    handles.append(model.fc.register_forward_hook(make_hook(\"fc\")))\n",
    "    for i, layer in enumerate(model.decoder):\n",
    "        lname = f\"decoder_{i}_{layer.__class__.__name__}\"\n",
    "        handles.append(layer.register_forward_hook(make_hook(lname)))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)  # shape (360, 1, 28, 28)\n",
    "    \n",
    "    # Remove hooks\n",
    "    for h in handles:\n",
    "        h.remove()\n",
    "    \n",
    "    # Also store final outputs\n",
    "    collected_activations[\"final_output\"] = outputs.detach().cpu()\n",
    "    \n",
    "    # ID vs. OOD mask\n",
    "    angles_deg = angles_rad.cpu().numpy() * 180 / np.pi\n",
    "    ood_mask = (angles_deg >= 140) & (angles_deg <= 200)\n",
    "    id_mask  = ~ood_mask\n",
    "    \n",
    "    # Plot\n",
    "    layer_names = sorted(collected_activations.keys())\n",
    "    fig, axes = plt.subplots(nrows=len(layer_names), ncols=1, figsize=(8, 4*len(layer_names)))\n",
    "    if len(layer_names) == 1:\n",
    "        axes = [axes]  # ensure list\n",
    "\n",
    "    for row_idx, layer_name in enumerate(layer_names):\n",
    "        ax = axes[row_idx]\n",
    "        act = flatten_activation(collected_activations[layer_name]).numpy()  # (360, ?)\n",
    "        \n",
    "        # UMAP\n",
    "        import umap\n",
    "        reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "        embedding = reducer.fit_transform(act)  # (360, 2)\n",
    "        \n",
    "        ax.scatter(embedding[id_mask, 0], embedding[id_mask, 1], \n",
    "                   c='blue', label='ID', s=30, alpha=0.7)\n",
    "        ax.scatter(embedding[ood_mask, 0], embedding[ood_mask, 1],\n",
    "                   c='red',  label='OOD', s=30, alpha=0.7)\n",
    "        \n",
    "        ax.set_title(f\"Digit 4 only: UMAP of '{layer_name}'\", fontsize=10)\n",
    "        ax.set_xlabel(\"UMAP-1\")\n",
    "        ax.set_ylabel(\"UMAP-2\")\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if store:\n",
    "        plt.savefig(\"./icml_figs_temp/umap_digit4_layers.png\", bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umap_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
